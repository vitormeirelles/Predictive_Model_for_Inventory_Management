{"cells":[{"cell_type":"code","source":["# Importar bibliotecas necessárias\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, to_date # to_date pode ser útil para futuras transformações de data\n","\n","# --- 1. Configuração do Ambiente e Caminhos ---\n","# A SparkSession já é gerenciada e disponibilizada automaticamente no Fabric.\n","# spark = SparkSession.builder.getOrCreate()\n","\n","# Nomes do Lakehouse e do Schema de destino\n","# Ambos têm o mesmo nome.\n","lakehouse_name = \"Projeto_II_Bronze_\"\n","target_schema_name = \"Projeto_II_Bronze_\"\n","\n","# Lista dos arquivos CSV que foram carregados manualmente para o diretório 'Files/'\n","csv_files_to_process = [\"cities.csv\", \"product.csv\", \"sales.csv\"]\n","\n","# Caminho base para os arquivos CSV dentro do diretório 'Files/'\n","csv_source_path_in_lakehouse = \"Files/\"\n","\n","print(f\"Iniciando o processo da Camada Bronze para o Lakehouse: '{lakehouse_name}'\")\n","print(f\"Schema de destino para as tabelas Delta: '{target_schema_name}'\")\n","print(f\"Arquivos CSV a serem processados: {csv_files_to_process}\")\n","print(f\"Caminho de origem dos CSVs (dentro do Lakehouse): '{csv_source_path_in_lakehouse}'\")\n","print(\"-\" * 80)\n","\n","# --- 2. Função Auxiliar para Processar um CSV e Salvar como Delta Table ---\n","\n","def process_csv_to_delta_bronze(spark_session, file_name, source_base_path, lh_name, schema_name):\n","    \"\"\"\n","    Lê um arquivo CSV de um caminho especificado no Lakehouse 'Files/'\n","    e o salva como uma tabela Delta em um schema específico dentro do mesmo Lakehouse.\n","    \"\"\"\n","    full_csv_path = f\"{source_base_path}{file_name}\"\n","    \n","    # O nome da tabela Delta será o nome do arquivo CSV (sem a extensão) + sufixo \"_bronze\"\n","    # Ex: cities.csv -> cities_bronze\n","    table_base_name = file_name.replace(\".csv\", \"\")\n","    full_delta_table_name = f\"{schema_name}.{table_base_name}_bronze\" # Nome qualificado com o schema\n","\n","    print(f\"\\nProcessando '{file_name}'...\")\n","    print(f\"Caminho completo do CSV de origem: {full_csv_path}\")\n","    print(f\"Nome da Tabela Delta de destino: {lh_name}.{full_delta_table_name}\")\n","\n","    try:\n","        # Lendo o arquivo CSV para um DataFrame Spark\n","        # .option(\"header\", \"true\") -> Assume que a primeira linha contém os nomes das colunas\n","        # .option(\"inferSchema\", \"true\") -> Tenta automaticamente adivinhar os tipos de dados das colunas\n","        df_raw = spark_session.read \\\n","            .option(\"header\", \"true\") \\\n","            .option(\"inferSchema\", \"true\") \\\n","            .csv(full_csv_path)\n","\n","        print(f\"DataFrame para '{file_name}' lido com sucesso. Exemplo de Schema Inferido:\")\n","        df_raw.printSchema()\n","        print(f\"Número de linhas detectadas: {df_raw.count()}\")\n","\n","        # Salvando o DataFrame como uma tabela Delta no schema especificado do Lakehouse.\n","        # .format(\"delta\") -> Especifica o formato Delta Lake.\n","        # .mode(\"overwrite\") -> Se a tabela já existir, ela será completamente substituída.\n","        # .saveAsTable(f\"{lh_name}.{full_delta_table_name}\") -> Salva o DataFrame como uma tabela gerenciada\n","        #                                                     no Catálogo do Spark e no Lakehouse,\n","        #                                                     no schema especificado.\n","        df_raw.write \\\n","            .format(\"delta\") \\\n","            .mode(\"overwrite\") \\\n","            .saveAsTable(f\"{lh_name}.{full_delta_table_name}\")\n","\n","        print(f\"Tabela Delta '{full_delta_table_name}' criada/atualizada com sucesso no Lakehouse '{lh_name}'.\")\n","\n","    except Exception as e:\n","        print(f\"ERRO: Falha ao processar '{file_name}'. Detalhes do erro: {e}\")\n","\n","# --- 3. Executar o Processamento para cada Arquivo CSV ---\n","\n","for csv_file in csv_files_to_process:\n","    process_csv_to_delta_bronze(spark, csv_file, csv_source_path_in_lakehouse, lakehouse_name, target_schema_name)\n","\n","# --- 4. Verificação Final das Tabelas Criadas (Opcional) ---\n","print(\"\\n\" + \"=\"*80)\n","print(\"--- VERIFICAÇÃO: Tabelas Delta Criadas na Camada Bronze ---\")\n","print(\"=\"*80)\n","\n","try:\n","    print(f\"\\nListando tabelas no schema '{target_schema_name}' do Lakehouse '{lakehouse_name}':\")\n","    # Usa Spark SQL para listar as tabelas no schema especificado\n","    spark.sql(f\"SHOW TABLES IN {lakehouse_name}.{target_schema_name}\").show()\n","\n","    # Mostrar algumas linhas de uma das tabelas para confirmar\n","    print(f\"\\nExemplo de dados da tabela '{target_schema_name}.sales_bronze':\")\n","    # Lendo a tabela Delta recém-criada\n","    df_sales_bronze_check = spark.read.format(\"delta\").table(f\"{lakehouse_name}.{target_schema_name}.sales_bronze\")\n","    df_sales_bronze_check.show(5) # Mostra as 5 primeiras linhas\n","    df_sales_bronze_check.printSchema() # Mostra o schema da tabela Delta\n","\n","except Exception as e:\n","    print(f\"Erro durante a verificação final: {e}\")\n","\n","print(\"\\n--- Processamento da Camada Bronze Concluído com Sucesso! ---\")\n","\n","# spark.stop() # Geralmente não é necessário no Fabric, a sessão é gerenciada automaticamente"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"e6e9fd47-233d-422e-aac2-962fa76a3b4b","normalized_state":"finished","queued_time":"2025-06-14T11:36:17.1642153Z","session_start_time":"2025-06-14T11:36:17.1652267Z","execution_start_time":"2025-06-14T11:36:29.3142191Z","execution_finish_time":"2025-06-14T11:37:15.3411616Z","parent_msg_id":"fc8a971f-e906-45d5-ab17-43a227127c09"},"text/plain":"StatementMeta(, e6e9fd47-233d-422e-aac2-962fa76a3b4b, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Iniciando o processo da Camada Bronze para o Lakehouse: 'Projeto_II_Bronze_'\nSchema de destino para as tabelas Delta: 'Projeto_II_Bronze_'\nArquivos CSV a serem processados: ['cities.csv', 'product.csv', 'sales.csv']\nCaminho de origem dos CSVs (dentro do Lakehouse): 'Files/'\n--------------------------------------------------------------------------------\n\nProcessando 'cities.csv'...\nCaminho completo do CSV de origem: Files/cities.csv\nNome da Tabela Delta de destino: Projeto_II_Bronze_.Projeto_II_Bronze_.cities_bronze\nDataFrame para 'cities.csv' lido com sucesso. Exemplo de Schema Inferido:\nroot\n |-- store_id: string (nullable = true)\n |-- storetype_id: string (nullable = true)\n |-- store_size: integer (nullable = true)\n |-- city_id_old: string (nullable = true)\n |-- country_id: string (nullable = true)\n |-- city_code: string (nullable = true)\n\nNúmero de linhas detectadas: 63\nTabela Delta 'Projeto_II_Bronze_.cities_bronze' criada/atualizada com sucesso no Lakehouse 'Projeto_II_Bronze_'.\n\nProcessando 'product.csv'...\nCaminho completo do CSV de origem: Files/product.csv\nNome da Tabela Delta de destino: Projeto_II_Bronze_.Projeto_II_Bronze_.product_bronze\nDataFrame para 'product.csv' lido com sucesso. Exemplo de Schema Inferido:\nroot\n |-- product_id: string (nullable = true)\n |-- product_length: double (nullable = true)\n |-- product_depth: double (nullable = true)\n |-- product_width: double (nullable = true)\n |-- cluster_id: string (nullable = true)\n |-- hierarchy1_id: string (nullable = true)\n |-- hierarchy2_id: string (nullable = true)\n |-- hierarchy3_id: string (nullable = true)\n |-- hierarchy4_id: string (nullable = true)\n |-- hierarchy5_id: string (nullable = true)\n\nNúmero de linhas detectadas: 699\nTabela Delta 'Projeto_II_Bronze_.product_bronze' criada/atualizada com sucesso no Lakehouse 'Projeto_II_Bronze_'.\n\nProcessando 'sales.csv'...\nCaminho completo do CSV de origem: Files/sales.csv\nNome da Tabela Delta de destino: Projeto_II_Bronze_.Projeto_II_Bronze_.sales_bronze\nDataFrame para 'sales.csv' lido com sucesso. Exemplo de Schema Inferido:\nroot\n |-- _c0: integer (nullable = true)\n |-- store_id: string (nullable = true)\n |-- product_id: string (nullable = true)\n |-- date: date (nullable = true)\n |-- sales: string (nullable = true)\n |-- revenue: string (nullable = true)\n |-- stock: string (nullable = true)\n |-- price: string (nullable = true)\n |-- promo_type_1: string (nullable = true)\n |-- promo_bin_1: string (nullable = true)\n |-- promo_type_2: string (nullable = true)\n |-- promo_bin_2: string (nullable = true)\n |-- promo_discount_2: string (nullable = true)\n |-- promo_discount_type_2: string (nullable = true)\n\nNúmero de linhas detectadas: 8886058\nTabela Delta 'Projeto_II_Bronze_.sales_bronze' criada/atualizada com sucesso no Lakehouse 'Projeto_II_Bronze_'.\n\n================================================================================\n--- VERIFICAÇÃO: Tabelas Delta Criadas na Camada Bronze ---\n================================================================================\n\nListando tabelas no schema 'Projeto_II_Bronze_' do Lakehouse 'Projeto_II_Bronze_':\n+--------------------+--------------+-----------+\n|           namespace|     tableName|isTemporary|\n+--------------------+--------------+-----------+\n|Projeto_II.Projet...| cities_bronze|      false|\n|Projeto_II.Projet...|product_bronze|      false|\n|Projeto_II.Projet...|  sales_bronze|      false|\n+--------------------+--------------+-----------+\n\n\nExemplo de dados da tabela 'Projeto_II_Bronze_.sales_bronze':\n+-------+--------+----------+----------+-----+-------+-----+-----+------------+-----------+------------+-----------+----------------+---------------------+\n|    _c0|store_id|product_id|      date|sales|revenue|stock|price|promo_type_1|promo_bin_1|promo_type_2|promo_bin_2|promo_discount_2|promo_discount_type_2|\n+-------+--------+----------+----------+-----+-------+-----+-----+------------+-----------+------------+-----------+----------------+---------------------+\n|5596964|   S0091|     P0220|2017-05-02|    0|      0|   20| 1.85|        PR14|         NA|        PR03|         NA|              NA|                   NA|\n|5596965|   S0091|     P0223|2017-05-02|    0|      0|   15| 10.9|        PR14|         NA|        PR03|         NA|              NA|                   NA|\n|5596966|   S0091|     P0227|2017-05-02|    0|      0|    4|  8.5|        PR14|         NA|        PR03|         NA|              NA|                   NA|\n|5596967|   S0091|     P0241|2017-05-02|    0|      0|    4|12.95|        PR05|    verylow|        PR03|         NA|              NA|                   NA|\n|5596968|   S0091|     P0242|2017-05-02|    0|      0|    6| 12.9|        PR14|         NA|        PR03|         NA|              NA|                   NA|\n+-------+--------+----------+----------+-----+-------+-----+-----+------------+-----------+------------+-----------+----------------+---------------------+\nonly showing top 5 rows\n\nroot\n |-- _c0: integer (nullable = true)\n |-- store_id: string (nullable = true)\n |-- product_id: string (nullable = true)\n |-- date: date (nullable = true)\n |-- sales: string (nullable = true)\n |-- revenue: string (nullable = true)\n |-- stock: string (nullable = true)\n |-- price: string (nullable = true)\n |-- promo_type_1: string (nullable = true)\n |-- promo_bin_1: string (nullable = true)\n |-- promo_type_2: string (nullable = true)\n |-- promo_bin_2: string (nullable = true)\n |-- promo_discount_2: string (nullable = true)\n |-- promo_discount_type_2: string (nullable = true)\n\n\n--- Processamento da Camada Bronze Concluído com Sucesso! ---\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3e3e973f-c874-4517-9324-6ffbcd765675"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"a042b393-ab15-4d5f-a23e-191e881ac79f"}],"default_lakehouse":"a042b393-ab15-4d5f-a23e-191e881ac79f","default_lakehouse_name":"Projeto_II_Bronze_","default_lakehouse_workspace_id":"206184e5-f2b5-4d4e-b443-0c5761a9b558"}}},"nbformat":4,"nbformat_minor":5}
