{"cells":[{"cell_type":"code","source":["# Importar bibliotecas necessárias para Spark\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import (\n","    col, lit, when, trim, coalesce, create_map, array, lower,\n","    year, month, dayofmonth, dayofweek, weekofyear, quarter, date_format\n",")\n","from pyspark.sql.types import DoubleType, IntegerType, StringType, DateType, DecimalType, BooleanType\n","\n","# Importar a biblioteca holidays para gerar os feriados da Turquia\n","import holidays\n","import pandas as pd\n","from datetime import date as dt_date # Para uso com a biblioteca holidays\n","\n","# --- 1. Configuração de Lakehouses e Schemas ---\n","# (Manter conforme já definido e corrigido)\n","bronze_lakehouse_name = \"Projeto_II_Bronze_\"\n","bronze_schema_name = \"Projeto_II_Bronze_\"\n","\n","silver_lakehouse_name = \"Projeto_II_Silver_\"\n","silver_schema_name = \"Projeto_II_Silver_\"\n","\n","gold_lakehouse_name = \"Projeto_II_Gold_\"\n","gold_schema_name = \"Projeto_II_Gold_\"\n","\n","\n","# --- Carregar tabelas Silver para processamento Gold ---\n","print(\"\\n--- Carregando tabelas Silver para processamento Gold ---\")\n","try:\n","    df_cities_silver = spark.read.format(\"delta\").table(f\"{silver_lakehouse_name}.{silver_schema_name}.cities_silver\")\n","    df_product_silver = spark.read.format(\"delta\").table(f\"{silver_lakehouse_name}.{silver_schema_name}.product_silver\")\n","    df_sales_silver = spark.read.format(\"delta\").table(f\"{silver_lakehouse_name}.{silver_schema_name}.sales_silver\")\n","    print(\"Tabelas Silver carregadas com sucesso.\")\n","except Exception as e:\n","    print(f\"ERRO: Falha ao carregar tabelas Silver. Detalhes do erro: {e}\")\n","    raise # É importante levantar o erro para parar a execução se as tabelas não puderem ser carregadas\n","\n","print(\"\\n\" + \"=\"*80)\n","print(f\"--- Processamento da Camada Silver para Gold Iniciado. ---\")\n","print(f\"Escrevendo no Lakehouse Gold: '{gold_lakehouse_name}', Schema: '{gold_schema_name}'\")\n","print(\"=\"*80)\n","\n","# --- Criação das Tabelas da Camada Gold ---\n","#\n","# --- 1. dim_stores ---\n","print(\"\\n--- Criando dim_stores na Camada Gold ---\")\n","try:\n","    dim_stores = df_cities_silver.select(\n","        col(\"store_id\").alias(\"store_id\"),\n","        col(\"storetype_id\"),\n","        col(\"store_size\"),\n","        col(\"city_name\")\n","    ).dropDuplicates([\"store_id\"])\n","\n","    dim_stores.write \\\n","        .format(\"delta\") \\\n","        .mode(\"overwrite\") \\\n","        .option(\"delta.logRetentionDuration\", \"interval 30 days\") \\\n","        .option(\"delta.deletedFileRetentionDuration\", \"interval 30 days\") \\\n","        .saveAsTable(f\"{gold_lakehouse_name}.{gold_schema_name}.dim_stores\")\n","\n","    print(f\"Tabela 'dim_stores' criada com sucesso no Lakehouse '{gold_lakehouse_name}'.\")\n","    dim_stores.printSchema()\n","    dim_stores.show(5)\n","\n","except Exception as e:\n","    print(f\"ERRO: Falha ao criar 'dim_stores'. Detalhes do erro: {e}\")\n","\n","# --- 2. dim_product ---\n","print(\"\\n--- Criando dim_product na Camada Gold ---\")\n","try:\n","    dim_product = df_product_silver.select(\n","        col(\"product_id\").alias(\"product_id\"),\n","        col(\"product_length\"),\n","        col(\"product_depth\"),\n","        col(\"product_width\"),\n","        col(\"cluster_id\"),\n","        col(\"hierarchy1_id\"),\n","        col(\"hierarchy2_id\"),\n","        col(\"hierarchy3_id\"),\n","        col(\"hierarchy4_id\"),\n","        col(\"hierarchy5_id\")\n","    ).dropDuplicates([\"product_id\"])\n","\n","    dim_product.write \\\n","        .format(\"delta\") \\\n","        .mode(\"overwrite\") \\\n","        .option(\"delta.logRetentionDuration\", \"interval 30 days\") \\\n","        .option(\"delta.deletedFileRetentionDuration\", \"interval 30 days\") \\\n","        .saveAsTable(f\"{gold_lakehouse_name}.{gold_schema_name}.dim_product\")\n","\n","    print(f\"Tabela 'dim_product' criada com sucesso no Lakehouse '{gold_lakehouse_name}'.\")\n","    dim_product.printSchema()\n","    dim_product.show(5)\n","\n","except Exception as e:\n","    print(f\"ERRO: Falha ao criar 'dim_product'. Detalhes do erro: {e}\")\n","\n","\n","# --- 3. dim_date (com is_holiday) ---\n","print(\"\\n--- Criando dim_date na Camada Gold (com is_holiday) ---\")\n","try:\n","    # 1. Obter todas as datas únicas da tabela de fatos para definir o intervalo\n","    df_distinct_dates = df_sales_silver.select(col(\"date\")).distinct().filter(col(\"date\").isNotNull())\n","\n","    # Converter para Pandas para encontrar o min/max date para a geração de feriados\n","    min_date_val = df_distinct_dates.agg({\"date\": \"min\"}).collect()[0][0]\n","    max_date_val = df_distinct_dates.agg({\"date\": \"max\"}).collect()[0][0]\n","\n","    # Ajustar para incluir o ano completo de início e fim\n","    start_year = min_date_val.year\n","    end_year = max_date_val.year\n","\n","    # 2. Gerar feriados da Turquia usando a biblioteca 'holidays'\n","    # 'TR' é o código ISO para Turquia\n","    turkey_holidays = holidays.CountryHoliday('TR', years=range(start_year, end_year + 1))\n","\n","    # Criar uma lista de tuplas (data_objeto, True) para os feriados\n","    holiday_data = [(date_obj, True) for date_obj in turkey_holidays.keys()]\n","\n","    # Criar um Pandas DataFrame e depois converter para Spark DataFrame\n","    df_holidays_pandas = pd.DataFrame(holiday_data, columns=['full_date', 'is_holiday_temp'])\n","    df_holidays_spark = spark.createDataFrame(df_holidays_pandas) \\\n","                             .withColumn(\"full_date\", col(\"full_date\").cast(DateType())) # Garantir DateType\n","\n","    # 3. Gerar a dim_date inicial sem is_holiday\n","    dim_date_base = df_distinct_dates.select(\n","        date_format(col(\"date\"), \"yyyyMMdd\").cast(IntegerType()).alias(\"date_id\"),\n","        col(\"date\").alias(\"full_date\"),\n","        year(col(\"date\")).alias(\"year\"),\n","        month(col(\"date\")).alias(\"month\"), # Aqui estava faltando um `.alias(\"month\")`\n","        dayofmonth(col(\"date\")).alias(\"day\"),\n","        dayofweek(col(\"date\")).alias(\"day_of_week_num\"),\n","        date_format(col(\"date\"), \"E\").alias(\"day_of_week_short\"),\n","        date_format(col(\"date\"), \"EEEE\").alias(\"day_of_week_long\"),\n","        weekofyear(col(\"date\")).alias(\"week_of_year\"),\n","        quarter(col(\"date\")).alias(\"quarter\"),\n","        date_format(col(\"date\"), \"MMMM\").alias(\"month_name_long\"),\n","        date_format(col(\"date\"), \"MMM\").alias(\"month_name_short\"),\n","        when(dayofweek(col(\"date\")).isin([1, 7]), True).otherwise(False).alias(\"is_weekend\")\n","    ).dropDuplicates([\"date_id\"])\n","\n","    # 4. Unir dim_date_base com df_holidays_spark para adicionar a coluna is_holiday\n","    dim_date_final = dim_date_base.alias(\"d\") \\\n","        .join(df_holidays_spark.alias(\"h\"), col(\"d.full_date\") == col(\"h.full_date\"), \"left_outer\") \\\n","        .select(\n","            col(\"d.date_id\"),\n","            col(\"d.full_date\"),\n","            col(\"d.year\"),\n","            col(\"d.month\"),\n","            col(\"d.day\"),\n","            col(\"d.day_of_week_num\"),\n","            col(\"d.day_of_week_short\"),\n","            col(\"d.day_of_week_long\"),\n","            col(\"d.week_of_year\"),\n","            col(\"d.quarter\"),\n","            col(\"d.month_name_long\"),\n","            col(\"d.month_name_short\"),\n","            col(\"d.is_weekend\"),\n","            coalesce(col(\"h.is_holiday_temp\"), lit(False)).cast(BooleanType()).alias(\"is_holiday\")\n","        )\n","\n","    dim_date_final.write \\\n","        .format(\"delta\") \\\n","        .mode(\"overwrite\") \\\n","        .option(\"delta.logRetentionDuration\", \"interval 30 days\") \\\n","        .option(\"delta.deletedFileRetentionDuration\", \"interval 30 days\") \\\n","        .saveAsTable(f\"{gold_lakehouse_name}.{gold_schema_name}.dim_date\")\n","\n","    print(f\"Tabela 'dim_date' criada com sucesso no Lakehouse '{gold_lakehouse_name}'.\")\n","    dim_date_final.printSchema()\n","    dim_date_final.show(5)\n","\n","except Exception as e:\n","    print(f\"ERRO: Falha ao criar 'dim_date'. Detalhes do erro: {e}\")\n","\n","# --- 4. fact_sales ---\n","print(\"\\n--- Criando fact_sales na Camada Gold ---\")\n","try:\n","    fact_sales = df_sales_silver.alias(\"s\") \\\n","        .join(dim_date_final.alias(\"dd\"), col(\"s.date\") == col(\"dd.full_date\"), \"inner\") \\\n","        .select(\n","            col(\"dd.date_id\"),\n","            col(\"s.store_id\"),\n","            col(\"s.product_id\"),\n","            \n","            col(\"s.sales\"),\n","            col(\"s.revenue\"),\n","            col(\"s.stock\"),\n","            col(\"s.price\"),\n","            \n","            col(\"s.promo_type_1\"),\n","            col(\"s.promo_bin_1\"),\n","            col(\"s.promo_type_2\"),\n","            col(\"s.promo_bin_2\"),\n","            \n","            col(\"s.promo_discount_2\"),\n","            col(\"s.promo_discount_type_2\")\n","        )\n","\n","    fact_sales.write \\\n","        .format(\"delta\") \\\n","        .mode(\"overwrite\") \\\n","        .option(\"delta.logRetentionDuration\", \"interval 30 days\") \\\n","        .option(\"delta.deletedFileRetentionDuration\", \"interval 30 days\") \\\n","        .saveAsTable(f\"{gold_lakehouse_name}.{gold_schema_name}.fact_sales\")\n","\n","    print(f\"Tabela 'fact_sales' criada com sucesso no Lakehouse '{gold_lakehouse_name}'.\")\n","    fact_sales.printSchema()\n","    fact_sales.show(5)\n","\n","except Exception as e:\n","    print(f\"ERRO: Falha ao criar 'fact_sales'. Detalhes do erro: {e}\")\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"--- Processamento da Camada Silver para Gold Concluído! ---\")\n","print(f\"As tabelas do Star Schema foram criadas no Lakehouse '{gold_lakehouse_name}', Schema '{gold_schema_name}'.\")\n","print(\"=\"*80)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"98114a7f-1dfb-4ec0-a4f3-669ce03f6fb9","normalized_state":"finished","queued_time":"2025-06-28T11:31:15.7693446Z","session_start_time":"2025-06-28T11:31:15.7707742Z","execution_start_time":"2025-06-28T11:31:25.0161384Z","execution_finish_time":"2025-06-28T11:32:38.2449073Z","parent_msg_id":"056f57ca-650b-4934-a4d7-ca0b4801c2c4"},"text/plain":"StatementMeta(, 98114a7f-1dfb-4ec0-a4f3-669ce03f6fb9, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n--- Carregando tabelas Silver para processamento Gold ---\nTabelas Silver carregadas com sucesso.\n\n================================================================================\n--- Processamento da Camada Silver para Gold Iniciado. ---\nEscrevendo no Lakehouse Gold: 'Projeto_II_Gold_', Schema: 'Projeto_II_Gold_'\n================================================================================\n\n--- Criando dim_stores na Camada Gold ---\nTabela 'dim_stores' criada com sucesso no Lakehouse 'Projeto_II_Gold_'.\nroot\n |-- store_id: string (nullable = true)\n |-- storetype_id: string (nullable = true)\n |-- store_size: integer (nullable = true)\n |-- city_name: string (nullable = true)\n\n+--------+------------+----------+---------+\n|store_id|storetype_id|store_size|city_name|\n+--------+------------+----------+---------+\n|   S0002|        ST04|        39|    Adana|\n|   S0003|        ST03|        17| Istanbul|\n|   S0005|        ST04|        19|  Denizli|\n|   S0007|        ST03|        16| Istanbul|\n|   S0010|        ST04|        17| Istanbul|\n+--------+------------+----------+---------+\nonly showing top 5 rows\n\n\n--- Criando dim_product na Camada Gold ---\nTabela 'dim_product' criada com sucesso no Lakehouse 'Projeto_II_Gold_'.\nroot\n |-- product_id: string (nullable = true)\n |-- product_length: double (nullable = true)\n |-- product_depth: double (nullable = true)\n |-- product_width: double (nullable = true)\n |-- cluster_id: string (nullable = true)\n |-- hierarchy1_id: string (nullable = true)\n |-- hierarchy2_id: string (nullable = true)\n |-- hierarchy3_id: string (nullable = true)\n |-- hierarchy4_id: string (nullable = true)\n |-- hierarchy5_id: string (nullable = true)\n\n+----------+--------------+-------------+-------------+---------------+-------------+-------------+-------------+-------------+-------------+\n|product_id|product_length|product_depth|product_width|     cluster_id|hierarchy1_id|hierarchy2_id|hierarchy3_id|hierarchy4_id|hierarchy5_id|\n+----------+--------------+-------------+-------------+---------------+-------------+-------------+-------------+-------------+-------------+\n|     P0000|           5.0|         20.0|         12.0|unknown_cluster|          H00|        H0004|      H000401|    H00040105|  H0004010534|\n|     P0001|          13.5|         22.0|         20.0|      cluster_5|          H01|        H0105|      H010501|    H01050100|  H0105010006|\n|     P0002|          22.0|         40.0|         22.0|      cluster_0|          H03|        H0315|      H031508|    H03150800|  H0315080028|\n|     P0004|           2.0|         13.0|          4.0|      cluster_3|          H03|        H0314|      H031405|    H03140500|  H0314050003|\n|     P0005|          16.0|         30.0|         16.0|      cluster_9|          H03|        H0312|      H031211|    H03121109|  H0312110917|\n+----------+--------------+-------------+-------------+---------------+-------------+-------------+-------------+-------------+-------------+\nonly showing top 5 rows\n\n\n--- Criando dim_date na Camada Gold (com is_holiday) ---\nTabela 'dim_date' criada com sucesso no Lakehouse 'Projeto_II_Gold_'.\nroot\n |-- date_id: integer (nullable = true)\n |-- full_date: date (nullable = true)\n |-- year: integer (nullable = true)\n |-- month: integer (nullable = true)\n |-- day: integer (nullable = true)\n |-- day_of_week_num: integer (nullable = true)\n |-- day_of_week_short: string (nullable = true)\n |-- day_of_week_long: string (nullable = true)\n |-- week_of_year: integer (nullable = true)\n |-- quarter: integer (nullable = true)\n |-- month_name_long: string (nullable = true)\n |-- month_name_short: string (nullable = true)\n |-- is_weekend: boolean (nullable = false)\n |-- is_holiday: boolean (nullable = false)\n\n+--------+----------+----+-----+---+---------------+-----------------+----------------+------------+-------+---------------+----------------+----------+----------+\n| date_id| full_date|year|month|day|day_of_week_num|day_of_week_short|day_of_week_long|week_of_year|quarter|month_name_long|month_name_short|is_weekend|is_holiday|\n+--------+----------+----+-----+---+---------------+-----------------+----------------+------------+-------+---------------+----------------+----------+----------+\n|20170102|2017-01-02|2017|    1|  2|              2|              Mon|          Monday|           1|      1|        January|             Jan|     false|     false|\n|20170103|2017-01-03|2017|    1|  3|              3|              Tue|         Tuesday|           1|      1|        January|             Jan|     false|     false|\n|20170104|2017-01-04|2017|    1|  4|              4|              Wed|       Wednesday|           1|      1|        January|             Jan|     false|     false|\n|20170105|2017-01-05|2017|    1|  5|              5|              Thu|        Thursday|           1|      1|        January|             Jan|     false|     false|\n|20170106|2017-01-06|2017|    1|  6|              6|              Fri|          Friday|           1|      1|        January|             Jan|     false|     false|\n+--------+----------+----+-----+---+---------------+-----------------+----------------+------------+-------+---------------+----------------+----------+----------+\nonly showing top 5 rows\n\n\n--- Criando fact_sales na Camada Gold ---\nTabela 'fact_sales' criada com sucesso no Lakehouse 'Projeto_II_Gold_'.\nroot\n |-- date_id: integer (nullable = true)\n |-- store_id: string (nullable = true)\n |-- product_id: string (nullable = true)\n |-- sales: double (nullable = true)\n |-- revenue: double (nullable = true)\n |-- stock: double (nullable = true)\n |-- price: double (nullable = true)\n |-- promo_type_1: string (nullable = true)\n |-- promo_bin_1: string (nullable = true)\n |-- promo_type_2: string (nullable = true)\n |-- promo_bin_2: string (nullable = true)\n |-- promo_discount_2: double (nullable = true)\n |-- promo_discount_type_2: string (nullable = true)\n\n+--------+--------+----------+-----+-------+-----+-----+------------+-----------+------------+-----------+----------------+---------------------+\n| date_id|store_id|product_id|sales|revenue|stock|price|promo_type_1|promo_bin_1|promo_type_2|promo_bin_2|promo_discount_2|promo_discount_type_2|\n+--------+--------+----------+-----+-------+-----+-----+------------+-----------+------------+-----------+----------------+---------------------+\n|20170811|   S0002|     P0005|  0.0|    0.0| 10.0| 33.9|        PR14|         NA|        PR03|         NA|             0.0|                   NA|\n|20170811|   S0002|     P0015|  0.0|    0.0|  8.0| 2.85|        PR10|        low|        PR03|         NA|             0.0|                   NA|\n|20170811|   S0002|     P0017| 10.0|  11.76| 22.0| 1.45|        PR10|    verylow|        PR03|         NA|             0.0|                   NA|\n|20170811|   S0002|     P0024|  0.0|    0.0| 18.0|  1.9|        PR14|         NA|        PR03|         NA|             0.0|                   NA|\n|20170811|   S0002|     P0035|  2.0|   7.87|  7.0| 4.25|        PR14|         NA|        PR03|         NA|             0.0|                   NA|\n+--------+--------+----------+-----+-------+-----+-----+------------+-----------+------------+-----------+----------------+---------------------+\nonly showing top 5 rows\n\n\n================================================================================\n--- Processamento da Camada Silver para Gold Concluído! ---\nAs tabelas do Star Schema foram criadas no Lakehouse 'Projeto_II_Gold_', Schema 'Projeto_II_Gold_'.\n================================================================================\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"376759b8-dcdc-4352-99d1-636e6c077990"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"2e40a180-143d-48d6-b79d-8d607a96a266"}],"default_lakehouse":"2e40a180-143d-48d6-b79d-8d607a96a266","default_lakehouse_name":"Projeto_II_Gold_","default_lakehouse_workspace_id":"206184e5-f2b5-4d4e-b443-0c5761a9b558"}}},"nbformat":4,"nbformat_minor":5}